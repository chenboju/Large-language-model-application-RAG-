{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chen\\AppData\\Local\\Temp\\ipykernel_68548\\3587039507.py:35: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings()\n",
      "C:\\Users\\chen\\AppData\\Local\\Temp\\ipykernel_68548\\3587039507.py:53: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, max_tokens=8192)\n",
      "c:\\Users\\chen\\anaconda3\\envs\\langchainragas\\lib\\site-packages\\langchain_core\\runnables\\history.py:608: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
      "  message_history = self.get_session_history(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– å›ç­”1ï¼š é€™ä»½æ–‡ä»¶ä¸»è¦è¨è«–äº†é«˜ç†µåˆé‡‘ï¼ˆHEAï¼‰å¡—å±¤çš„å¾®è§€çµæ§‹å’Œè€ç£¨æ€§èƒ½ï¼Œç‰¹åˆ¥æ˜¯é€šéTIGè¦†è“‹æŠ€è¡“è£½å‚™çš„CoCrFeMnNbNié«˜ç†µåˆé‡‘å¡—å±¤ã€‚æ–‡ä»¶ä¸­æ¯”è¼ƒäº†AISI 304é‹¼å’Œé«˜ç†µåˆé‡‘å¡—å±¤åœ¨ç£¨æè¡¨é¢ä¸Šçš„å¾®è§€çµæ§‹ï¼ŒæŒ‡å‡ºé«˜ç†µåˆé‡‘å¡—å±¤åœ¨ä¹¾æ»‘å‹•ç£¨ææ¢ä»¶ä¸‹å…·æœ‰å„ªç•°çš„è€ç£¨æ€§ï¼Œä¸¦ä¸”å…¶ç£¨æè¡¨é¢çš„å¾®çŠç¾è±¡è¼ƒæ·ºä¸”è¼ƒç´°ï¼Œé€™èˆ‡Lavesç›¸çš„ç´ç±³å°ºåº¦å±¤ç‹€çµæ§‹çš„å½¢æˆæœ‰é—œã€‚æ–‡ä»¶é‚„æåˆ°é€™ç¨®å¡—å±¤çš„çµ„æˆè®ŠåŒ–å°å…¶æ€§èƒ½çš„å½±éŸ¿ã€‚\n",
      "ğŸ¤– å›ç­”2ï¼š æ–‡ä»¶ä¸­æåˆ°çš„é‡‘å±¬ææ–™åŒ…æ‹¬éˆ·ï¼ˆCoï¼‰ã€é‰»ï¼ˆCrï¼‰ã€éµï¼ˆFeï¼‰ã€éŒ³ï¼ˆMnï¼‰ã€éˆ®ï¼ˆNbï¼‰å’Œé³ï¼ˆNiï¼‰ã€‚é€™äº›é‡‘å±¬è¢«ç”¨ä¾†è£½å‚™é«˜ç†µåˆé‡‘å¡—å±¤ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "# âœ… è¨­å®š OpenAI é‡‘é‘°\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api key\"\n",
    "\n",
    "# âœ… è®€å– PDF\n",
    "pdf_dir = \"./PDF\"  # â† ç¢ºä¿é€™å€‹è³‡æ–™å¤¾å­˜åœ¨ä¸”æœ‰ PDF\n",
    "all_documents = []\n",
    "\n",
    "for file in os.listdir(pdf_dir):\n",
    "    if file.lower().endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_dir, file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load()\n",
    "        all_documents.extend(pages)\n",
    "\n",
    "# âœ… åˆ†å‰²æ–‡æœ¬\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
    "documents = splitter.split_documents(pages)\n",
    "\n",
    "# âœ… å»ºç«‹å‘é‡è³‡æ–™åº« (Chroma)\n",
    "persist_directory = \"./chroma_pdf_db\"\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding_model,\n",
    "    persist_directory=persist_directory,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# âœ… å»ºç«‹æç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä½ææ–™ç§‘å­¸åŠ©ç†ï¼Œè«‹æ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”å•é¡Œã€‚\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# âœ… å»ºç«‹ LLM èˆ‡æ–‡ä»¶éˆ\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, max_tokens=8192)\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# âœ… å®šç¾© SQL-based è¨˜æ†¶å„²å­˜\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///./langchain.db\")\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    retrieval_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    output_messages_key=\"answer\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# âœ… å•Ÿå‹•å°è©±ï¼ˆæ¸¬è©¦ï¼‰\n",
    "session_id = str(uuid.uuid4())  # æ¯æ¬¡åŸ·è¡Œéƒ½ç”¨æ–°çš„ sessionï¼Œå¯æ”¹ç‚ºå›ºå®šå€¼æ¸¬è©¦\n",
    "config = {\"configurable\": {\"session_id\": session_id}}\n",
    "\n",
    "response1 = chain_with_history.invoke({\"input\": \"è«‹å•åœ¨ç›®å‰çš„é«˜ç†µåˆé‡‘æ‡‰ç”¨ä¸­ï¼Œå“ªäº›å…ƒç´ çµ„åˆå¸¸è¦‹æ–¼å‚¬åŒ–åŠ‘ï¼Ÿ\"}, config=config)\n",
    "print(\"ğŸ¤– å›ç­”1ï¼š\", response1[\"answer\"])\n",
    "\n",
    "response2 = chain_with_history.invoke({\"input\": \"input\": \"å“ªä¸€çµ„çš„è¡¨ç¾æ¯”è¼ƒå¥½ï¼Ÿ\"}, config=config)\n",
    "print(\"ğŸ¤– å›ç­”2ï¼š\", response2[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– å›ç­”1ï¼š åœ¨é«˜ç†µåˆé‡‘ï¼ˆHEAsï¼‰æ‡‰ç”¨æ–¼å‚¬åŒ–åŠ‘çš„ç ”ç©¶ä¸­ï¼Œå¸¸è¦‹çš„å…ƒç´ çµ„åˆåŒ…æ‹¬éæ¸¡é‡‘å±¬å…ƒç´ ï¼Œå¦‚é³ï¼ˆNiï¼‰ã€éˆ·ï¼ˆCoï¼‰ã€éµï¼ˆFeï¼‰ã€éŠ…ï¼ˆCuï¼‰ã€é‰»ï¼ˆCrï¼‰ã€éŒ³ï¼ˆMnï¼‰ç­‰ã€‚é€™äº›å…ƒç´ çš„çµ„åˆå¯ä»¥å½¢æˆå…·æœ‰å¤šæ¨£æ€§å’Œç©©å®šæ€§çš„åˆé‡‘ç³»çµ±ï¼Œé€™äº›ç‰¹æ€§å°æ–¼å‚¬åŒ–åŠ‘çš„æ€§èƒ½æå‡éå¸¸æœ‰åˆ©ã€‚æ­¤å¤–ï¼ŒæŸäº›ç ”ç©¶ä¹ŸæœƒåŠ å…¥è²´é‡‘å±¬å…ƒç´ å¦‚é‰‘ï¼ˆPtï¼‰ã€éˆ€ï¼ˆPdï¼‰ç­‰ï¼Œä»¥é€²ä¸€æ­¥æé«˜å‚¬åŒ–æ´»æ€§å’Œé¸æ“‡æ€§ã€‚é€™äº›é«˜ç†µåˆé‡‘å‚¬åŒ–åŠ‘åœ¨å¤šç›¸å‚¬åŒ–ã€é›»å‚¬åŒ–å’Œå…‰å‚¬åŒ–ç­‰é ˜åŸŸå±•ç¾å‡ºæ½›åŠ›ã€‚\n",
      "ğŸ¤– å›ç­”2ï¼š é«˜ç†µåˆé‡‘åœ¨å‚¬åŒ–åŠ‘æ‡‰ç”¨ä¸­çš„è¡¨ç¾å–æ±ºæ–¼å…·é«”çš„åæ‡‰å’Œæ‡‰ç”¨å ´æ™¯ï¼Œå› æ­¤å¾ˆé›£å–®ç´”åœ°èªªå“ªä¸€çµ„å…ƒç´ çš„è¡¨ç¾æœ€å¥½ã€‚ç„¶è€Œï¼Œä¸€äº›ç ”ç©¶è¡¨æ˜ï¼ŒåŒ…å«è²´é‡‘å±¬å¦‚é‰‘ï¼ˆPtï¼‰å’Œéˆ€ï¼ˆPdï¼‰çš„é«˜ç†µåˆé‡‘åœ¨æŸäº›å‚¬åŒ–åæ‡‰ä¸­è¡¨ç¾å‡ºè‰²ï¼Œç‰¹åˆ¥æ˜¯åœ¨éœ€è¦é«˜å‚¬åŒ–æ´»æ€§å’Œé¸æ“‡æ€§çš„åæ‡‰ä¸­ã€‚\n",
      "\n",
      "å¦ä¸€æ–¹é¢ï¼Œå®Œå…¨ç”±éæ¸¡é‡‘å±¬çµ„æˆçš„é«˜ç†µåˆé‡‘ï¼ˆå¦‚Niã€Coã€Feã€Cuã€Crã€Mnç­‰ï¼‰åœ¨æˆæœ¬å’Œç©©å®šæ€§æ–¹é¢å…·æœ‰å„ªå‹¢ï¼Œä¸¦ä¸”åœ¨æŸäº›å·¥æ¥­æ‡‰ç”¨ä¸­ä¹Ÿèƒ½æä¾›è‰¯å¥½çš„å‚¬åŒ–æ€§èƒ½ã€‚\n",
      "\n",
      "å› æ­¤ï¼Œé¸æ“‡å“ªä¸€çµ„å…ƒç´ çµ„åˆå–æ±ºæ–¼å…·é«”çš„æ‡‰ç”¨éœ€æ±‚ã€æˆæœ¬è€ƒé‡ä»¥åŠæ‰€éœ€çš„å‚¬åŒ–æ€§èƒ½ã€‚ç ”ç©¶äººå“¡é€šå¸¸æœƒæ ¹æ“šé€™äº›å› ç´ é€²è¡Œå„ªåŒ–å’Œèª¿æ•´ï¼Œä»¥é”åˆ°æœ€ä½³çš„å‚¬åŒ–æ•ˆæœã€‚\n"
     ]
    }
   ],
   "source": [
    "# âœ… å•Ÿå‹•å°è©±ï¼ˆæ¸¬è©¦ï¼‰\n",
    "session_id = str(uuid.uuid4())  # æ¯æ¬¡åŸ·è¡Œéƒ½ç”¨æ–°çš„ sessionï¼Œå¯æ”¹ç‚ºå›ºå®šå€¼æ¸¬è©¦\n",
    "config = {\"configurable\": {\"session_id\": session_id}}\n",
    "\n",
    "response1 = chain_with_history.invoke({\"input\": \"è«‹å•åœ¨ç›®å‰çš„é«˜ç†µåˆé‡‘æ‡‰ç”¨ä¸­ï¼Œå“ªäº›å…ƒç´ çµ„åˆå¸¸è¦‹æ–¼å‚¬åŒ–åŠ‘ï¼Ÿ\"}, config=config)\n",
    "print(\"ğŸ¤– å›ç­”1ï¼š\", response1[\"answer\"])\n",
    "\n",
    "response2 = chain_with_history.invoke({\"input\":\"å“ªä¸€çµ„çš„è¡¨ç¾æ¯”è¼ƒå¥½ï¼Ÿ\"}, config=config)\n",
    "print(\"ğŸ¤– å›ç­”2ï¼š\", response2[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

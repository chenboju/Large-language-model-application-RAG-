{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cohere ç‰ˆæœ¬</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¡ï¸ è‹±æ–‡æŸ¥è©¢ rerank çµæœæ•¸é‡: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "# âœ… API Key è¨­å®š\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api key\"\n",
    "os.environ[\"COHERE_API_KEY\"] = \"api key\"\n",
    "\n",
    "# âœ… è¼‰å…¥è³‡æ–™èˆ‡å»ºæ§‹ Chroma å‘é‡åº«\n",
    "persist_dir = \"./chroma_db\"\n",
    "text_units_df = pd.read_json(\"é«˜å•†åˆé‡‘0406_text_units.json\", lines=True)\n",
    "embeddings_df = pd.read_json(\"é«˜å•†åˆé‡‘0406_embeddings.text_unit.text.json\", lines=True)\n",
    "data_df = pd.merge(text_units_df, embeddings_df, on=\"id\")\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=row[\"text\"], metadata={\"id\": row[\"id\"]})\n",
    "    for _, row in data_df.iterrows()\n",
    "]\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 100})\n",
    "\n",
    "# âœ… æç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a professional assistant specializing in materials science and engineering.\n",
    "        Your main role is to help users search, analyze, and summarize materials-related literature and data.\n",
    "        Always provide factual, source-backed responses and clearly state when information is uncertain or not available.\n",
    "        When applicable, extract key material properties (e.g., conductivity, thermal stability, mechanical strength) and link them to relevant studies or datasets.\n",
    "        Avoid making assumptions not supported by data.\\n\\n{context}\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# âœ… è¨­å®š LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, max_tokens=8192)\n",
    "\n",
    "# âœ… å»ºç«‹æ–‡ä»¶å•ç­”éˆ\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# âœ… å»ºç«‹ Cohere reranker\n",
    "reranker = CohereRerank(top_n=5, model=\"rerank-english-v2.0\")\n",
    "\n",
    "# âœ… è‡ªå®šç¾© retriever åŒ…å« rerank\n",
    "class RerankRetriever:\n",
    "    def __init__(self, base_retriever, reranker):\n",
    "        self._base_retriever = base_retriever\n",
    "        self._reranker = reranker\n",
    "\n",
    "    def get_relevant_documents(self, query: str):\n",
    "        # å–å¾—å€™é¸æ–‡ä»¶ï¼ˆé€™è£¡å¾—åˆ°çš„æ˜¯ä¸€å€‹ Document ç‰©ä»¶åˆ—è¡¨ï¼‰\n",
    "        docs = self._base_retriever.get_relevant_documents(query)\n",
    "        # æå–æ–‡æœ¬å…§å®¹ï¼Œå› ç‚º Cohere Rerank API éœ€è¦ä¸€å€‹æ–‡å­—åˆ—è¡¨\n",
    "        doc_texts = [doc.page_content for doc in docs]\n",
    "        \n",
    "        # ä½¿ç”¨å‘½ååƒæ•¸ï¼Œå‚³å…¥ query åŠç´”æ–‡å­—æ–‡ä»¶åˆ—è¡¨\n",
    "        reranked_texts = self._reranker.rerank(query=query, documents=doc_texts)\n",
    "        \n",
    "        # ç”±æ–¼ reranker API è¿”å›çš„æ˜¯é‡æ’åºå¾Œçš„æ–‡ä»¶æ–‡å­—åˆ—è¡¨\n",
    "        # ä½ å¯ä»¥ä¾æ“šè¿”å›çš„çµæœé †åºï¼Œåœ¨åŸå§‹çš„å€™é¸æ–‡ä»¶ä¸­æŒ‘é¸å‡ºå°æ‡‰çš„ Document\n",
    "        # é€™è£¡å‡è¨­è¿”å›çš„æ–‡å­—èˆ‡åŸæœ¬çš„ text å®Œå…¨ä¸€è‡´ï¼Œæ‰€ä»¥ç”¨ä¸€å€‹ç°¡å–®æ¯”å°ä¾†é‚„åŸæ–‡ä»¶ç‰©ä»¶\n",
    "        reranked_docs = []\n",
    "        for text in reranked_texts:\n",
    "            for doc in docs:\n",
    "                if doc.page_content == text:\n",
    "                    reranked_docs.append(doc)\n",
    "                    break\n",
    "        return reranked_docs\n",
    "\n",
    "\n",
    "# âœ… åŒ…è£ retriever\n",
    "rerank_retriever = RerankRetriever(retriever, reranker)\n",
    "\n",
    "# âœ… å»ºç«‹ Retrieval Chain with rerank\n",
    "# retrieval_chain_with_rerank = create_retrieval_chain(rerank_retriever, document_chain)\n",
    "# æ‰‹å‹•çµ„åˆ retrieval + document_chain\n",
    "\n",
    "retrieval_chain_with_rerank = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: rerank_retriever.get_relevant_documents(x[\"input\"]),\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"history\": lambda x: x.get(\"history\", [])\n",
    "    }) \n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "# âœ… å®šç¾© SQL è¨˜æ†¶å„²å­˜\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///./langchain.db\")\n",
    "\n",
    "# âœ… åŒ…è£æˆå…·è¨˜æ†¶åŠŸèƒ½çš„å¤šè¼ªå°è©±éˆï¼ˆä½¿ç”¨ rerank ç‰ˆæœ¬ï¼‰\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    retrieval_chain_with_rerank,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    output_messages_key=\"answer\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "\n",
    "query_en = \"Which element combinations are commonly used in high-entropy alloy catalysts?\"\n",
    "docs_test = rerank_retriever.get_relevant_documents(query_en)\n",
    "print(f\"â¡ï¸ è‹±æ–‡æŸ¥è©¢ rerank çµæœæ•¸é‡: {len(docs_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hugging Face ç‰ˆæœ¬</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chen\\anaconda3\\envs\\langchainragas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "c:\\Users\\chen\\anaconda3\\envs\\langchainragas\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chen\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¡ï¸ è‹±æ–‡æŸ¥è©¢ rerank çµæœæ•¸é‡: 5\n",
      "\n",
      "ğŸ”¹ Top 1: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 2: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 3: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 4: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 5: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "# âœ… å®‰è£éœ€å…ˆæ‰‹å‹•åŸ·è¡Œï¼špip install sentence-transformers\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# âœ… HuggingFace Reranker é¡åˆ¥ï¼ˆå–ä»£ Cohereï¼‰\n",
    "class HF_Reranker:\n",
    "    def __init__(self, model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\", top_n=5):\n",
    "        self.model = CrossEncoder(model_name)\n",
    "        self.top_n = top_n\n",
    "\n",
    "    def rerank(self, query, documents):\n",
    "        pairs = [[query, doc] for doc in documents]\n",
    "        scores = self.model.predict(pairs)\n",
    "        scored_docs = list(zip(documents, scores))\n",
    "        scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_docs = [doc for doc, _ in scored_docs[:self.top_n]]\n",
    "        return top_docs\n",
    "\n",
    "# âœ… API Key è¨­å®šï¼ˆHF ä¸éœ€ï¼‰\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api key\"\n",
    "\n",
    "# âœ… è¼‰å…¥è³‡æ–™èˆ‡å»ºæ§‹ Chroma å‘é‡åº«\n",
    "persist_dir = \"./chroma_db\"\n",
    "text_units_df = pd.read_json(\"é«˜å•†åˆé‡‘0406_text_units.json\", lines=True)\n",
    "embeddings_df = pd.read_json(\"é«˜å•†åˆé‡‘0406_embeddings.text_unit.text.json\", lines=True)\n",
    "data_df = pd.merge(text_units_df, embeddings_df, on=\"id\")\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=row[\"text\"], metadata={\"id\": row[\"id\"]})\n",
    "    for _, row in data_df.iterrows()\n",
    "]\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 100})\n",
    "\n",
    "# âœ… æç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a professional assistant specializing in materials science and engineering.\n",
    "        Your main role is to help users search, analyze, and summarize materials-related literature and data.\n",
    "        Always provide factual, source-backed responses and clearly state when information is uncertain or not available.\n",
    "        When applicable, extract key material properties (e.g., conductivity, thermal stability, mechanical strength) and link them to relevant studies or datasets.\n",
    "        Avoid making assumptions not supported by data.\\n\\n{context}\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# âœ… è¨­å®š LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, max_tokens=8192)\n",
    "\n",
    "# âœ… å»ºç«‹æ–‡ä»¶å•ç­”éˆ\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# âœ… ä½¿ç”¨ HF rerankerï¼ˆå–ä»£ Cohereï¼‰\n",
    "reranker = HF_Reranker(top_n=5)\n",
    "\n",
    "# âœ… è‡ªå®šç¾© retriever åŒ…å« rerank\n",
    "class RerankRetriever:\n",
    "    def __init__(self, base_retriever, reranker):\n",
    "        self._base_retriever = base_retriever\n",
    "        self._reranker = reranker\n",
    "\n",
    "    def get_relevant_documents(self, query: str):\n",
    "        docs = self._base_retriever.get_relevant_documents(query)\n",
    "        doc_texts = [doc.page_content for doc in docs]\n",
    "        reranked_texts = self._reranker.rerank(query=query, documents=doc_texts)\n",
    "        reranked_docs = []\n",
    "        for text in reranked_texts:\n",
    "            for doc in docs:\n",
    "                if doc.page_content == text:\n",
    "                    reranked_docs.append(doc)\n",
    "                    break\n",
    "        return reranked_docs\n",
    "\n",
    "# âœ… åŒ…è£ retriever\n",
    "rerank_retriever = RerankRetriever(retriever, reranker)\n",
    "\n",
    "# âœ… å»ºç«‹ Retrieval Chain with rerank\n",
    "retrieval_chain_with_rerank = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: rerank_retriever.get_relevant_documents(x[\"input\"]),\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"history\": lambda x: x.get(\"history\", [])\n",
    "    }) \n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "# âœ… å®šç¾© SQL è¨˜æ†¶å„²å­˜\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///./langchain.db\")\n",
    "\n",
    "# âœ… åŒ…è£å¤šè¼ªå°è©±éˆ\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    retrieval_chain_with_rerank,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    output_messages_key=\"answer\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# âœ… æ¸¬è©¦ HuggingFace rerank çµæœ\n",
    "query_en = \"Which element combinations are commonly used in high-entropy alloy catalysts?\"\n",
    "docs_test = rerank_retriever.get_relevant_documents(query_en)\n",
    "print(f\"â¡ï¸ è‹±æ–‡æŸ¥è©¢ rerank çµæœæ•¸é‡: {len(docs_test)}\")\n",
    "for i, doc in enumerate(docs_test, 1):\n",
    "    print(f\"\\nğŸ”¹ Top {i}: {doc.page_content[:300]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª åŸå§‹æª¢ç´¢çµæœæ•¸é‡: 100\n",
      "\n",
      "ğŸ”¹ Doc 1 é è¦½ï¼šodes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Doc 2 é è¦½ï¼šodes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Doc 3 é è¦½ï¼šodes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "â¡ï¸ rerank çµæœæ•¸é‡: 5\n",
      "\n",
      "ğŸ”¹ Top 1: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 2: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 3: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 4: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n",
      "\n",
      "ğŸ”¹ Top 5: odes. \n",
      "They exhibit a high hydrogen evolution potential, which limits the \n",
      "hydrogen evolution reaction [16]. In the aluminium industry, primary \n",
      "aluminium typically contains approximately 0.1 wt% Fe after the \n",
      "smelting process. In response to demands for sustainable development, a \n",
      "significant porti\n"
     ]
    }
   ],
   "source": [
    "docs_raw = retriever.get_relevant_documents(query_en)\n",
    "print(f\"ğŸ§ª åŸå§‹æª¢ç´¢çµæœæ•¸é‡: {len(docs_raw)}\")\n",
    "for i, doc in enumerate(docs_raw[:3], 1):\n",
    "    print(f\"\\nğŸ”¹ Doc {i} é è¦½ï¼š{doc.page_content[:300]}\")\n",
    "\n",
    "docs_test = rerank_retriever.get_relevant_documents(query_en)\n",
    "print(f\"â¡ï¸ rerank çµæœæ•¸é‡: {len(docs_test)}\")\n",
    "for i, doc in enumerate(docs_test, 1):\n",
    "    print(f\"\\nğŸ”¹ Top {i}: {doc.page_content[:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” æŸ¥çœ‹é€™å€‹ query è¢« rerank é¸ä¸­çš„å‰äº”ç¯‡æ–‡ä»¶\n",
    "query_zh = \"è«‹å•åœ¨ç›®å‰çš„é«˜ç†µåˆé‡‘æ‡‰ç”¨ä¸­ï¼Œå“ªäº›å…ƒç´ çµ„åˆå¸¸è¦‹æ–¼å‚¬åŒ–åŠ‘ï¼Ÿ\"\n",
    "docs_reranked = rerank_retriever.get_relevant_documents(query_zh)\n",
    "\n",
    "print(\"\\nğŸ“Š è¢«é¸ä¸­çš„ Top 5 æ–‡æª”å¦‚ä¸‹ï¼š\")\n",
    "for i, doc in enumerate(docs_reranked, 1):\n",
    "    print(f\"\\nğŸ”¹ Top {i}:\")\n",
    "    print(doc.page_content[:500])  # é¡¯ç¤ºå‰ 500 å­—\n",
    "    print(f\"ğŸ“ ID: {doc.metadata.get('id')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('answer')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨é«˜ç†µåˆé‡‘ï¼ˆHigh-Entropy Alloys, HEAsï¼‰ä½œç‚ºå‚¬åŒ–åŠ‘çš„æ‡‰ç”¨ä¸­ï¼Œä»¥ä¸‹å…ƒç´ çµ„åˆè¼ƒç‚ºå¸¸è¦‹ï¼š\n",
      "\n",
      "1. **Ni-Co-Fe-Cr-Mn**ï¼šé€™çµ„åˆåœ¨æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰å’Œæ°«æ¼”åŒ–åæ‡‰ï¼ˆHERï¼‰ä¸­è¢«å»£æ³›ç ”ç©¶ï¼Œå› ç‚ºé€™äº›å…ƒç´ æä¾›äº†è‰¯å¥½çš„å‚¬åŒ–æ´»æ€§å’Œç©©å®šæ€§ã€‚\n",
      "\n",
      "2. **Pt-Pd-Rh-Ru-Ir**ï¼šé€™äº›è²´é‡‘å±¬çµ„åˆåœ¨å‚¬åŒ–åŠ‘ä¸­éå¸¸å¸¸è¦‹ï¼Œç‰¹åˆ¥æ˜¯åœ¨æ±½è»Šå°¾æ°£è™•ç†å’Œç‡ƒæ–™é›»æ± ä¸­ï¼Œå› ç‚ºå®ƒå€‘å…·æœ‰å„ªç•°çš„å‚¬åŒ–æ€§èƒ½ã€‚\n",
      "\n",
      "3. **Cu-Ni-Co-Cr-Fe**ï¼šé€™çµ„åˆåœ¨ç”²çƒ·é‡æ•´å’Œå…¶ä»–ç¢³æ°«åŒ–åˆç‰©è½‰åŒ–åæ‡‰ä¸­è¡¨ç¾å‡ºè‰²ï¼Œå› ç‚ºå®ƒå€‘èƒ½æœ‰æ•ˆåœ°ä¿ƒé€²åæ‡‰ä¸¦æé«˜é¸æ“‡æ€§ã€‚\n",
      "\n",
      "4. **V-Nb-Ta-Mo-W**ï¼šé€™äº›éæ¸¡é‡‘å±¬çµ„åˆåœ¨æ°¨åˆæˆå’Œå…¶ä»–é«˜æº«å‚¬åŒ–åæ‡‰ä¸­è¢«ç ”ç©¶ï¼Œå› ç‚ºå®ƒå€‘å…·æœ‰é«˜ç†”é»å’Œè‰¯å¥½çš„åŒ–å­¸ç©©å®šæ€§ã€‚\n",
      "\n",
      "é€™äº›çµ„åˆçš„é¸æ“‡é€šå¸¸åŸºæ–¼å®ƒå€‘çš„é›»å­çµæ§‹ã€åŸå­åŠå¾‘ã€ç†”é»å’ŒåŒ–å­¸ç©©å®šæ€§ç­‰å› ç´ ï¼Œä»¥å„ªåŒ–å‚¬åŒ–æ€§èƒ½å’Œè€ä¹…æ€§ã€‚å…·é«”çš„æ‡‰ç”¨å’Œæ€§èƒ½é‚„éœ€æ ¹æ“šå¯¦é©—æ•¸æ“šå’Œç†è«–è¨ˆç®—é€²è¡Œé€²ä¸€æ­¥é©—è­‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('answer')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¦ç¢ºå®šå“ªä¸€çµ„é«˜ç†µåˆé‡‘åœ¨å‚¬åŒ–æ‡‰ç”¨ä¸­è¡¨ç¾è¼ƒå¥½ï¼Œé€šå¸¸éœ€è¦å…·é«”çš„å¯¦é©—æ•¸æ“šå’Œæ‡‰ç”¨èƒŒæ™¯ã€‚ä¸åŒçš„åˆé‡‘çµ„åˆåœ¨ä¸åŒçš„å‚¬åŒ–åæ‡‰ä¸­å¯èƒ½è¡¨ç¾å‡ºä¸åŒçš„å„ªå‹¢ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›è€ƒé‡å› ç´ ï¼š\n",
      "\n",
      "1. **æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰å’Œæ°«æ¼”åŒ–åæ‡‰ï¼ˆHERï¼‰**ï¼šNi-Co-Fe-Cr-Mnçµ„åˆåœ¨é€™äº›åæ‡‰ä¸­é€šå¸¸è¡¨ç¾è‰¯å¥½ï¼Œå› ç‚ºé€™äº›å…ƒç´ èƒ½æä¾›è‰¯å¥½çš„å‚¬åŒ–æ´»æ€§å’Œç©©å®šæ€§ã€‚\n",
      "\n",
      "2. **è²´é‡‘å±¬å‚¬åŒ–åŠ‘**ï¼šPt-Pd-Rh-Ru-Irçµ„åˆåœ¨è¨±å¤šå‚¬åŒ–æ‡‰ç”¨ä¸­è¡¨ç¾å‡ºè‰²ï¼Œç‰¹åˆ¥æ˜¯åœ¨æ±½è»Šå°¾æ°£è™•ç†å’Œç‡ƒæ–™é›»æ± ä¸­ï¼Œå› ç‚ºå®ƒå€‘å…·æœ‰å„ªç•°çš„å‚¬åŒ–æ€§èƒ½ã€‚ç„¶è€Œï¼Œé€™äº›åˆé‡‘çš„é«˜æˆæœ¬å¯èƒ½é™åˆ¶å…¶å¤§è¦æ¨¡æ‡‰ç”¨ã€‚\n",
      "\n",
      "3. **é«˜æº«åæ‡‰**ï¼šV-Nb-Ta-Mo-Wçµ„åˆåœ¨é«˜æº«å‚¬åŒ–åæ‡‰ä¸­å¯èƒ½è¡¨ç¾è¼ƒå¥½ï¼Œå› ç‚ºå®ƒå€‘å…·æœ‰é«˜ç†”é»å’Œè‰¯å¥½çš„åŒ–å­¸ç©©å®šæ€§ã€‚\n",
      "\n",
      "4. **ç¢³æ°«åŒ–åˆç‰©è½‰åŒ–**ï¼šCu-Ni-Co-Cr-Feçµ„åˆåœ¨ç”²çƒ·é‡æ•´å’Œå…¶ä»–ç¢³æ°«åŒ–åˆç‰©è½‰åŒ–åæ‡‰ä¸­è¡¨ç¾å‡ºè‰²ï¼Œå› ç‚ºå®ƒå€‘èƒ½æœ‰æ•ˆåœ°ä¿ƒé€²åæ‡‰ä¸¦æé«˜é¸æ“‡æ€§ã€‚\n",
      "\n",
      "æœ€çµ‚ï¼Œå“ªä¸€çµ„åˆè¡¨ç¾è¼ƒå¥½éœ€è¦æ ¹æ“šå…·é«”çš„æ‡‰ç”¨éœ€æ±‚ã€æ“ä½œæ¢ä»¶å’Œç¶“æ¿Ÿè€ƒé‡ä¾†æ±ºå®šã€‚å¯¦é©—ç ”ç©¶å’Œç†è«–è¨ˆç®—æ˜¯è©•ä¼°é€™äº›åˆé‡‘æ€§èƒ½çš„é—œéµã€‚è‹¥æœ‰å…·é«”çš„æ‡‰ç”¨æˆ–åæ‡‰éœ€æ±‚ï¼Œå»ºè­°åƒè€ƒç›¸é—œçš„ç§‘å­¸æ–‡ç»å’Œç ”ç©¶å ±å‘Šä»¥ç²å–æ›´æº–ç¢ºçš„ä¿¡æ¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "# âœ… å¤šè¼ªæŸ¥è©¢ï¼šä½¿ç”¨ç›¸åŒ session_id é€²è¡Œå°è©±\n",
    "config = {\"configurable\": {\"session_id\": \"chad-session-0408\"}}\n",
    "\n",
    "# ç¬¬ä¸€è¼ªæå•\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"è«‹å•åœ¨ç›®å‰çš„é«˜ç†µåˆé‡‘æ‡‰ç”¨ä¸­ï¼Œå“ªäº›å…ƒç´ çµ„åˆå¸¸è¦‹æ–¼å‚¬åŒ–åŠ‘ï¼Ÿ\"},\n",
    "    config=config\n",
    ")\n",
    "print(response1)\n",
    "\n",
    "# ç¬¬äºŒè¼ªæå•ï¼ˆå»¶çºŒä¸Šä¸€é¡Œï¼‰\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"å“ªä¸€çµ„çš„è¡¨ç¾æ¯”è¼ƒå¥½ï¼Ÿ\"},\n",
    "    config=config\n",
    ")\n",
    "print(response2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

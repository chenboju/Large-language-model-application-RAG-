{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè®€å– OPENAI_API_KEY\n",
      "âœ… LLM æ¸¬è©¦å›æ‡‰ï¼š Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"âœ… æˆåŠŸè®€å– OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰è®€å–åˆ° OPENAI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”\")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=1)\n",
    "response = llm.invoke(\"hello\")\n",
    "print(\"âœ… LLM æ¸¬è©¦å›æ‡‰ï¼š\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jsonç‰ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic_retrieval_gpt4o.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"âœ… æˆåŠŸè®€å– OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰è®€å–åˆ° OPENAI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”\")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=1)\n",
    "response = llm.invoke(\"hello\")\n",
    "print(\"âœ… LLM æ¸¬è©¦å›æ‡‰ï¼š\", response.content)\n",
    "\n",
    "# âœ… è®€å–è³‡æ–™\n",
    "# âœ… è¼‰å…¥è³‡æ–™\n",
    "text_units = pd.read_json(\"50PDF0409_text_units.json\", lines=True)\n",
    "embeddings = pd.read_json(\"50PDF0409_embeddings.text_unit.text.json\", lines=True)\n",
    "\n",
    "id2text = dict(zip(text_units[\"id\"], text_units[\"text\"]))\n",
    "id2embedding = dict(zip(embeddings[\"id\"], embeddings[\"embedding\"]))\n",
    "documents = [\n",
    "    Document(page_content=id2text[_id], metadata={\"id\": _id})\n",
    "    for _id in id2text if _id in id2embedding\n",
    "]\n",
    "\n",
    "# âœ… å»ºç«‹å‘é‡åº« (Chroma)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "\n",
    "# âœ… åˆå§‹åŒ– GPT-4o\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "\n",
    "# âœ… æå•\n",
    "query = \"å“ªäº›é«˜ç†µåˆé‡‘å¸¸è¢«ç”¨æ–¼å‚¬åŒ–åæ‡‰ï¼Ÿ\"\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "# âœ… é¡¯ç¤ºæª¢ç´¢çµæœ\n",
    "print(\"\\nğŸ” å‰ 5 ç­†æª¢ç´¢æ®µè½ï¼š\\n\")\n",
    "for i, doc in enumerate(docs):\n",
    "    snippet = doc.page_content[:100].replace(\"\\n\", \" \")\n",
    "    print(f\"{i+1}. (id: {doc.metadata['id']}) {snippet}...\\n\")\n",
    "\n",
    "# âœ… åˆæˆ Prompt ä¸¦è©¢å• GPT-4o\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆç²¾æ–¼ææ–™ç§‘å­¸çš„åŠ©ç†ï¼Œè«‹æ ¹æ“šä»¥ä¸‹æ®µè½å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n",
    "=== æª¢ç´¢å…§å®¹ ===\n",
    "{context}\n",
    "\n",
    "=== ä½¿ç”¨è€…å•é¡Œ ===\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "prompt = prompt_template.format_messages(context=context, question=query)\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(\"ğŸ§  GPT-4o å›ç­”ï¼š\\n\" + \"-\" * 50 + f\"\\n{response.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chen\\anaconda3\\envs\\langchainragas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\chen\\AppData\\Local\\Temp\\ipykernel_38316\\330972986.py:28: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” å‘é‡æª¢ç´¢ + CrossEncoder é‡æ’åºå‰ 5ï¼š\n",
      "\n",
      "1. (id: bdaf8a8137198e7e00fab055c91b2042f1e715aa02c9eb199f5058cba9b47fcc25408af3cb19046da99f6ceb06ed3f1813e92f23ba98ae2288d80058dfd1525c)  the product, but also shape, size, and distri-\n",
      "bution of the pores in the proposed structure. This ...\n",
      "\n",
      "2. (id: 38424cc2d18388a3cd91e0cd84d2ef1b0e32006753c6dbc45b1e24f0e6448f2106fa190335913a0174069d738659b1c04a31f766bf50f2cb75eb6fda037f4b89) nic Technology Co., Ltd. after single â€sided polishing\n",
      "treatment. 2,3,6,7,10,11 â€hexaaminotriphenyle...\n",
      "\n",
      "3. (id: 4a20a58e3757134db8b62ef79183ee52f9202aaf2b227ad2551a518de9c57d98c87af5ed529083cce83bbd7175a743ece27267f85bb0f47ffff9d3e844b27ed8) tes [ 6]. In the MABs with alkaline electrolytes, KOH, NaOH,\n",
      "and LiOH are the most commonly used. KO...\n",
      "\n",
      "4. (id: a80a08afa3d9c10efea9935f693b628bef96c4a13d246a41a785a74c306b5211b7ee6676d05f1467c3349631b0294ea45ebd100dc51414b0344a1f91341010ea) materials\n",
      "Article\n",
      "Corrosion Resistance of the CpTi G2 Cellular Lattice with\n",
      "TPMS Architecture for Ga...\n",
      "\n",
      "5. (id: 79814230c0d86aef95a34967e9a5edd4d5002d75269c47d6af3a88a5b81221803a9a001679b72a49798a3a0b2fde77962537e1890a1b6e6149d2c61aa2369d0d) ,\n",
      "corrosion resistance, and high-temperature strength [ 15,16]. They are categorized based on\n",
      "their ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chen\\AppData\\Local\\Temp\\ipykernel_38316\\330972986.py:57: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  GPT-4o å›ç­”ï¼š\n",
      "--------------------------------------------------\n",
      "åœ¨æª¢ç´¢å…§å®¹ä¸­ä¸¦æœªç›´æ¥æåˆ°é«˜ç†µåˆé‡‘åŠå…¶åœ¨å‚¬åŒ–ä¸­çš„æ‡‰ç”¨ã€‚å› æ­¤ï¼Œæ ¹æ“šæä¾›çš„è³‡æ–™ï¼Œæˆ‘ç„¡æ³•å›ç­”é€™å€‹å•é¡Œã€‚é«˜ç†µåˆé‡‘æ˜¯ä¸€é¡ç”±å¤šç¨®å…ƒç´ çµ„æˆçš„åˆé‡‘ï¼Œé€šå¸¸å…·æœ‰å„ªç•°çš„æ©Ÿæ¢°æ€§èƒ½å’Œè€è…è•æ€§ï¼Œä¸¦åœ¨å‚¬åŒ–ã€èƒ½æºå’Œèˆªç©ºèˆªå¤©ç­‰é ˜åŸŸæœ‰æ½›åœ¨æ‡‰ç”¨ã€‚å¦‚æœéœ€è¦æ›´è©³ç´°çš„ä¿¡æ¯ï¼Œå»ºè­°æŸ¥é–±ç›¸é—œçš„ç§‘å­¸æ–‡ç»æˆ–è³‡æ–™åº«ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# semantic_rerank_gpt4o.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"âœ… æˆåŠŸè®€å– OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰è®€å–åˆ° OPENAI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”\")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=1)\n",
    "response = llm.invoke(\"hello\")\n",
    "print(\"âœ… LLM æ¸¬è©¦å›æ‡‰ï¼š\", response.content)\n",
    "# âœ… è¼‰å…¥æ–‡æœ¬èˆ‡åµŒå…¥è³‡æ–™\n",
    "text_units = pd.read_json(\"50PDF0409_text_units.json\", lines=True)\n",
    "embeddings = pd.read_json(\"50PDF0409_embeddings.text_unit.text.json\", lines=True)\n",
    "\n",
    "id2text = dict(zip(text_units[\"id\"], text_units[\"text\"]))\n",
    "id2embedding = dict(zip(embeddings[\"id\"], embeddings[\"embedding\"]))\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=id2text[_id], metadata={\"id\": _id})\n",
    "    for _id in id2text if _id in id2embedding\n",
    "]\n",
    "\n",
    "# âœ… Chroma å‘é‡è³‡æ–™åº«ï¼ˆæš«å­˜ï¼‰\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# âœ… æŸ¥è©¢\n",
    "query = \"å“ªäº›é«˜ç†µåˆé‡‘å¸¸è¢«æ‡‰ç”¨æ–¼å‚¬åŒ–ï¼Ÿ\"\n",
    "initial_docs = retriever.invoke(query)\n",
    "\n",
    "# âœ… CrossEncoder ç²¾ç´°æ’åº\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "rerank_inputs = [(query, doc.page_content) for doc in initial_docs]\n",
    "scores = reranker.predict(rerank_inputs)\n",
    "\n",
    "# âœ… æ’åºä¸¦å–å‰ 5\n",
    "scored_docs = list(zip(scores, initial_docs))\n",
    "scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "top_docs = [doc for _, doc in scored_docs[:5]]\n",
    "\n",
    "# âœ… é¡¯ç¤º top 5\n",
    "print(\"\\nğŸ” å‘é‡æª¢ç´¢ + CrossEncoder é‡æ’åºå‰ 5ï¼š\\n\")\n",
    "for i, doc in enumerate(top_docs):\n",
    "    print(f\"{i+1}. (id: {doc.metadata['id']}) {doc.page_content[:100]}...\\n\")\n",
    "\n",
    "# âœ… GPT-4o å›ç­”\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in top_docs)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ææ–™ç§‘å­¸ç ”ç©¶åŠ©ç†ï¼Œè«‹æ ¹æ“šä»¥ä¸‹æ®µè½å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚\n",
    "=== æª¢ç´¢å…§å®¹ ===\n",
    "{context}\n",
    "\n",
    "=== ä½¿ç”¨è€…å•é¡Œ ===\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "prompt = prompt_template.format_messages(context=context, question=query)\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(\"ğŸ§  GPT-4o å›ç­”ï¼š\\n\" + \"-\" * 50 + f\"\\n{response.content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "vecs = embedding_model.embed_documents([\"test\"])\n",
    "print(len(vecs[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFç‰ˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader,PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureChatOpenAI,AzureOpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.vectorstores import Chroma\n",
    "# from qdrant_client import QdrantClient\n",
    "# from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from typing import Dict\n",
    "from langchain.schema.runnable import RunnableMap, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè®€å– OPENAI_API_KEY\n",
      "âœ… LLM æ¸¬è©¦å›æ‡‰ï¼š Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"âœ… æˆåŠŸè®€å– OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰è®€å–åˆ° OPENAI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”\")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=1)\n",
    "response = llm.invoke(\"hello\")\n",
    "print(\"âœ… LLM æ¸¬è©¦å›æ‡‰ï¼š\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! frequency_penalty is not default parameter.\n",
      "                    frequency_penalty was transferred to model_kwargs.\n",
      "                    Please confirm that frequency_penalty is what you intended.\n"
     ]
    }
   ],
   "source": [
    "generator_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",   # æˆ– \"gpt-4\", \"gpt-3.5-turbo\"\n",
    "    temperature=0.3,       # æ§åˆ¶å›ç­”ç©©å®šæ€§ã€‚æ¨è–¦å€¼ï¼š0~0.3ï¼ˆä»»å‹™å°å‘ï¼‰ï¼Œ0.7~1ï¼ˆå‰µæ„ä»»å‹™ï¼‰\n",
    "    max_tokens=8192,       # æ§åˆ¶å›æ‡‰é•·åº¦ã€‚æ¨è–¦æ ¹æ“šä»»å‹™èª¿æ•´ï¼Œå¦‚æ‘˜è¦å¯çŸ­ï¼ŒæŠ€è¡“å•ç­”å¯è¨­é•·\n",
    "    # top_p=1,               # Nucleus samplingï¼Œèˆ‡ temperature äºŒé¸ä¸€ï¼Œé è¨­ä¸å‹•\n",
    "    frequency_penalty=1,   # æ¸›å°‘é‡è¤‡å­—è©ï¼ˆ0~2ï¼‰\n",
    "    # presence_penalty=0,    # é¼“å‹µæ–°è©±é¡Œï¼ˆ0~2ï¼‰\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:29<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¸½å…±è¼‰å…¥ 799 ç¯‡æ–‡ä»¶\n",
      "ç¸½å…±åˆ†å‰²æˆ 8605 å€‹ chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… æ‰¹æ¬¡è¼‰å…¥æ•´å€‹ PDF è³‡æ–™å¤¾\n",
    "pdf_loader = DirectoryLoader(\n",
    "    path=\"../PDF\",                     # â† æ ¹æ“šä½  notebook æ‰€åœ¨ä½ç½®èª¿æ•´\n",
    "    glob=\"**/*.pdf\",                  # æ‰€æœ‰å­ç›®éŒ„ä¸‹çš„ PDF éƒ½æŠ“\n",
    "    loader_cls=PyPDFLoader,           # æ¯ä¸€ä»½ PDF ä½¿ç”¨ PyPDFLoader è§£æ\n",
    "    show_progress=True                # é¡¯ç¤ºé€²åº¦\n",
    ")\n",
    "\n",
    "documents = pdf_loader.load()         # è®€å–æ‰€æœ‰ PDF æ–‡ä»¶ç‰©ä»¶\n",
    "print(f\"ç¸½å…±è¼‰å…¥ {len(documents)} ç¯‡æ–‡ä»¶\")  # æª¢æŸ¥æ˜¯å¦è®€åˆ°æ‰€æœ‰æ–‡ä»¶\n",
    "\n",
    "# # ä½¿ç”¨ PyPDFDirectoryLoaderï¼ˆæ¯å€‹ PDF åªçµ¦ä¸€å€‹ documentï¼‰\n",
    "# pdf_loader = PyPDFDirectoryLoader(\"../PDF\")\n",
    "# documents = pdf_loader.load()\n",
    "\n",
    "# print(f\"ç¸½å…±è¼‰å…¥ {len(documents)} ä»½ PDF æ–‡ä»¶\")  # å°±æœƒæ˜¯çœŸæ­£çš„ PDF æª”æ•¸\n",
    "\n",
    "\n",
    "\n",
    "# âœ… åˆ†æ®µï¼šä¸€ä»½ PDF åˆ‡æˆå¤šå€‹ chunkï¼ˆæº–å‚™é€åµŒå…¥ï¼‰\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits = splitter.split_documents(documents)\n",
    "print(f\"ç¸½å…±åˆ†å‰²æˆ {len(splits)} å€‹ chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chen\\AppData\\Local\\Temp\\ipykernel_38604\\2721908531.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    chunk_size=16  # æ¯æ¬¡é€ 16 æ®µå»åµŒå…¥\n",
    ")\n",
    "\n",
    "# âœ… å»ºç«‹å‘é‡åº«\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    "    # persist_directory=\"./chroma_db\"  # å¯æ›æˆä½ æƒ³å­˜çš„ä½ç½®\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \n",
    "     \"\"\"You are a research assistant specializing in materials science and engineering, with expertise in literature summarization, property analysis, and application interpretation.\n",
    "Please help the user search for and organize information related to materials according to the following principles:\n",
    "\n",
    "- Your responses must be based on reliable sources or literature, and all sources should be clearly cited.\n",
    "- Do not fabricate data. If data is missing or unavailable, explicitly state â€œno data availableâ€ or â€œnot mentioned in the literature.â€\n",
    "- If multiple entries meet the query criteria, present them in a comparison table.\n",
    "- Use clear, objective, and academic language suitable for direct inclusion in technical reports.\n",
    "- Please format each summary using the following structure:\n",
    "    \\n\\n{context}\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… å»ºç«‹ Retriever\n",
    "# retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_concat(inputs: Dict[str, str]) -> str:\n",
    "    query = inputs[\"question\"]\n",
    "    top_k = inputs.get(\"top_k\", 5)\n",
    "\n",
    "    # ğŸŸ¡ ä½¿ç”¨å‹•æ…‹è¨­å®šçš„ k\n",
    "    custom_retriever = vectorstore.as_retriever(search_kwargs={\"k\": top_k})\n",
    "    docs = custom_retriever.get_relevant_documents(query)\n",
    "\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        meta = doc.metadata\n",
    "        context += f\"[{i+1}] ä¾†æºï¼š{meta.get('source', 'æœªçŸ¥')}ï¼Œç¬¬ {meta.get('page', '?')} é \\n\"\n",
    "        context += doc.page_content + \"\\n\\n\"\n",
    "    return context\n",
    "\n",
    "retriever_chain = RunnableLambda(retrieve_and_concat)\n",
    "\n",
    "# âœ… QA Chain çµ„åˆ\n",
    "qa_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever_chain,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"history\": lambda x: [] \n",
    "    })\n",
    "    | prompt\n",
    "    | generator_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å•é¡Œï¼š è«‹å•æœ‰å“ªäº›é«˜ç†µåˆé‡‘é©åˆæ‡‰ç”¨æ–¼æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰ï¼Ÿ\n",
      "ğŸ¤– å›ç­”ï¼š ä»¥ä¸‹æ˜¯ä¸€äº›é©åˆç”¨æ–¼æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰çš„é«˜ç†µåˆé‡‘ï¼Œæ ¹æ“šä¸åŒçš„æ–‡ç»è³‡æ–™é€²è¡Œæ•´ç†ï¼š\n",
      "\n",
      "| åˆé‡‘çµ„æˆ | ç‰¹æ€§ | ä¾†æº |\n",
      "|---------|------|------|\n",
      "| CoCrFeNiPd | å…·æœ‰å„ªç•°çš„å‚¬åŒ–æ´»æ€§å’Œç©©å®šæ€§ï¼Œé©åˆåœ¨é…¸æ€§ä»‹è³ªä¸­ä½¿ç”¨ã€‚ | [1] Yu, 2022, Carbon Energy, ç¬¬42é  |\n",
      "| FeCoNiCuPt | å±•ç¤ºå‡ºé«˜æ•ˆçš„æ°§é‚„åŸå‚¬åŒ–æ€§èƒ½ï¼Œç‰¹åˆ¥æ˜¯åœ¨é¹¼æ€§ä»‹è³ªä¸­ã€‚ | [2] LÃ¶ffler et al., Adv Energy Mater, 2018; 8(34):1802269 |\n",
      "| PtRuCuOsIr (å¤šå­”çµæ§‹) | å¢å¼·äº†ç”²é†‡æ°§åŒ–å’Œæ°§é‚„åŸæ´»æ€§çš„é›»å‚¬åŒ–æ€§èƒ½ã€‚ | [3] Chen et al., Journal of Power Sources, 2015 |\n",
      "\n",
      "é€™äº›é«˜ç†µåˆé‡‘å› å…¶å¤šå…ƒçµ„åˆ†å’Œç¨ç‰¹çš„å¾®è§€çµæ§‹ï¼Œä½¿å…¶åœ¨é›»å‚¬åŒ–æ‡‰ç”¨ä¸­å±•ç¾å‡ºå„ªç•°çš„æ€§èƒ½ã€‚\n",
      "\n",
      "ä¾†æºï¼š\n",
      "[1] Yu - Highâ€entropy alloy catalysts: From bulk to nano toward highly efficient carbon and nitrogen catalysis - Carbon Energy\n",
      "[2] LÃ¶ffler T , Meyer H , Savan A , et al. Discovery of a multinary noble metal-free oxygen reduction catalyst . Adv Energy Mater . 2018 ; 8(34):1802269.\n",
      "[3] Chen X., Si C., Gao Y., Frenzel J., Sun J., Eggeler G. and Zhang Z. Multi-component nanoporous platinumâ€“rutheniumâ€“copperâ€“osmiumâ€“iridium alloy with enhanced electrocatalytic activity towards methanol oxidation and oxygen reduction. Journal of Power Sources, 273:324-332.\n",
      "\n",
      "å¦‚æœéœ€è¦æ›´è©³ç´°çš„ä¿¡æ¯æˆ–å…¶ä»–ç›¸é—œææ–™ï¼Œå¯ä»¥åƒè€ƒä¸Šè¿°æ–‡ç»ä¸­çš„å…·é«”æ•¸æ“šå’Œè¨è«–ã€‚\n"
     ]
    }
   ],
   "source": [
    "# âœ… ä½¿ç”¨ç¯„ä¾‹ï¼ˆå« top_kï¼‰\n",
    "query_input = {\n",
    "    \"question\": \"è«‹å•æœ‰å“ªäº›é«˜ç†µåˆé‡‘é©åˆæ‡‰ç”¨æ–¼æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰ï¼Ÿ\",\n",
    "    \"top_k\": 5\n",
    "}\n",
    "\n",
    "print(\"ğŸ§ª å•é¡Œï¼š\", query_input[\"question\"])\n",
    "\n",
    "response = qa_chain.invoke(query_input)\n",
    "print(\"ğŸ¤– å›ç­”ï¼š\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str):\n",
    "    return InMemoryChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_with_memory = RunnableWithMessageHistory(\n",
    "    qa_chain,                        # ä½ åŸæœ¬çš„ QA chain\n",
    "    get_session_history,            # è¨˜æ†¶å–å¾—å‡½å¼\n",
    "    input_messages_key=\"question\",  # å•é¡Œåœ¨å“ªå€‹æ¬„ä½\n",
    "    # output_messages_key=\"answer\",   # å›ç­”æœƒå­˜åœ¨é€™è£¡\n",
    "    history_messages_key=\"history\"  # prompt éœ€è¦çš„ history\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ç‚ºäº†è©•ä¼°å“ªä¸€çµ„åˆé‡‘çš„è¡¨ç¾æœ€å¥½ï¼Œæˆ‘å€‘éœ€è¦è€ƒæ…®å¤šå€‹å› ç´ ï¼ŒåŒ…æ‹¬æ©Ÿæ¢°æ€§èƒ½ï¼ˆå¦‚æŠ—æ‹‰å¼·åº¦ã€å»¶å±•æ€§ï¼‰ã€è€è…è•æ€§ã€ç†±ç©©å®šæ€§ç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¾†è‡ªä¸åŒæ–‡ç»çš„åˆé‡‘æ€§èƒ½æ¯”è¼ƒï¼š\\n\\n| åˆé‡‘é¡å‹ | æŠ—æ‹‰å¼·åº¦ (MPa) | å»¶å±•æ€§ (%) | è€è…è•æ€§ | ç†±ç©©å®šæ€§ |\\n|----------|-----------------|------------|----------|----------|\\n| CoCrFeMnNi é«˜ç†µåˆé‡‘ [2] | 700-900         | 40-50      | è‰¯å¥½     | å„ªè‰¯     |\\n| FeCoNiCrTi0.2 é«˜ç†µåˆé‡‘ [3]  | >1000           | 20-30      | æœªæåŠ   | è‰¯å¥½     |\\n\\nä¾†æºï¼š\\n[1] J.J. Kai, K. Lu, Y. Liu, C.T. Liu, Multicomponent intermetallic nanoparticles and superb mechanical behaviors of complex alloys, Science 362 (2018) 933 e937.\\n[2] S.J. Sun et al., Modulating the prestrain history to optimize strength and ductility in CoCrFeMnNi high-entropy alloy, Scripta Mater., https://doi.org/10.1016/j.scriptamat.2019.01.012.\\n[3] Y.Tong et al., Outstanding tensile properties of a precipitation-strengthened FeCoNiCrTi0.2 high-entropy alloy at room and cryogenic temperatures, Acta Mater.\\n\\nå¾ä¸Šè¡¨å¯ä»¥çœ‹å‡ºï¼ŒFeCoNiCrTi0.2 é«˜ç†µåˆé‡‘åœ¨æŠ—æ‹‰å¼·åº¦æ–¹é¢è¡¨ç¾å„ªç•°ï¼Œä½†å…¶å»¶å±•æ€§ç›¸å°è¼ƒä½ï¼Œè€Œ CoCrFeMnNi åˆé‡‘å‰‡åœ¨å»¶å±•æ€§å’Œç†±ç©©å®šæ€§æ–¹é¢æœ‰æ›´å¥½çš„å¹³è¡¡ã€‚å› æ­¤ï¼Œå“ªä¸€çµ„åˆé‡‘â€œæœ€å¥½â€å–æ±ºæ–¼å…·é«”æ‡‰ç”¨éœ€æ±‚ã€‚å¦‚æœéœ€è¦é«˜å¼·åº¦ï¼Œå¯èƒ½é¸æ“‡ FeCoNiCrTi0.2ï¼›å¦‚æœéœ€è¦æ›´å¥½çš„ç¶œåˆæ€§èƒ½å’Œå¹³è¡¡ï¼Œå‰‡å¯èƒ½é¸æ“‡ CoCrFeMnNiã€‚'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"user_123\"  # æ¯ä½ä½¿ç”¨è€…æˆ–å°è©±ä¸€å€‹å”¯ä¸€ ID\n",
    "    }\n",
    "}\n",
    "\n",
    "# ç¬¬ä¸€å¥\n",
    "qa_chain_with_memory.invoke(\n",
    "    {\"question\": \"è«‹å•æœ‰å“ªäº›é«˜ç†µåˆé‡‘é©åˆæ‡‰ç”¨æ–¼ORRï¼Ÿ\", \"top_k\": 5},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒå¥ï¼ˆä¸Šä¸‹æ–‡æœƒæ¥è‘—ä¸Šé¢ï¼‰\n",
    "qa_chain_with_memory.invoke(\n",
    "    {\"question\": \"å“ªä¸€çµ„åˆé‡‘çš„è¡¨ç¾æœ€å¥½ï¼Ÿ\", \"top_k\": 3},\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å•é¡Œï¼š è«‹å•æœ‰å“ªäº›é«˜ç†µåˆé‡‘é©åˆæ‡‰ç”¨æ–¼æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰ï¼Ÿ\n",
      "ğŸ¤– å›ç­”ï¼š ä»¥ä¸‹æ˜¯ä¸€äº›é©åˆæ‡‰ç”¨æ–¼æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰çš„é«˜ç†µåˆé‡‘ï¼Œæ ¹æ“šæ–‡ç»ä¸­çš„è³‡æ–™æ•´ç†å¦‚ä¸‹ï¼š\n",
      "\n",
      "| åˆé‡‘çµ„æˆ | ç‰¹æ€§ | ä¾†æº |\n",
      "|---------|-----|------|\n",
      "| ç„¡è²´é‡‘å±¬å¤šå…ƒåˆé‡‘ | ç™¼ç¾äº†ä¸€ç¨®ç„¡è²´é‡‘å±¬çš„å¤šå…ƒæ°§é‚„åŸå‚¬åŒ–åŠ‘ï¼Œå…·æœ‰å„ªç•°çš„å‚¬åŒ–æ´»æ€§ã€‚é€™ç¨®ææ–™åœ¨é™ä½æˆæœ¬å’Œæé«˜æ•ˆç‡æ–¹é¢å…·æœ‰æ½›åŠ›ã€‚ | [1] LÃ¶ffler T, Meyer H, Savan A, et al. Discovery of a multinary noble metal-free oxygen reduction catalyst. Adv Energy Mater. 2018; 8(34):1802269. |\n",
      "| å¤šçµ„åˆ†ç´ç±³å­”åˆé‡‘/(æ°§)æ°«æ°§åŒ–ç‰© | ç”¨æ–¼é›™åŠŸèƒ½æ°§é›»å‚¬åŒ–å’Œå¯å……é›»é‹…ç©ºæ°£é›»æ± ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„æ€§èƒ½ã€‚é€™é¡ææ–™åœ¨èƒ½é‡è½‰æ›è£ç½®ä¸­æœ‰é‡è¦æ‡‰ç”¨åƒ¹å€¼ã€‚ | [2] Fang G, Gao J, Lv J, et al. Multi-component nanoporous alloy/(oxy)hydroxide for bifunctional oxygen electrocatalysis and rechargeable Zn-air batteries. Appl Catal B Environ. 2020; 268:118431.|\n",
      "\n",
      "é€™äº›é«˜ç†µåˆé‡‘å› å…¶ç¨ç‰¹çš„çµ„æˆå’Œçµæ§‹ï¼Œä½¿å…¶åœ¨ORRä¸­å±•ç¾å‡ºå„ªç•°çš„æ€§èƒ½ï¼Œä¸¦ä¸”æä¾›äº†é™ä½è²´é‡ææ–™ä½¿ç”¨é‡çš„æ–°é€”å¾‘ã€‚\n",
      "\n",
      "ä¾†æºï¼š\n",
      "[1] Yu - Highâ€entropy alloy catalysts: From bulk to nano toward highly efficient carbon and nitrogen catalysis - Carbon Energy - Wiley Online Library.\n",
      "[2] åŒä¸Šæ–‡ç»\n"
     ]
    }
   ],
   "source": [
    "# âœ… æŒ‡å®šå°è©±å…§å®¹èˆ‡åƒæ•¸\n",
    "query_input = {\n",
    "    \"question\": \"è«‹å•æœ‰å“ªäº›é«˜ç†µåˆé‡‘é©åˆæ‡‰ç”¨æ–¼æ°§é‚„åŸåæ‡‰ï¼ˆORRï¼‰ï¼Ÿ\",\n",
    "    \"top_k\": 5\n",
    "}\n",
    "\n",
    "# âœ… æŒ‡å®šå°è©± session IDï¼ˆå¯æ›æˆä½¿ç”¨è€…å¸³è™Ÿã€UUID ç­‰ï¼‰\n",
    "session_id = \"user_124\"\n",
    "\n",
    "# âœ… å‘¼å«åŒ…å«è¨˜æ†¶çš„ QA Chain\n",
    "print(\"ğŸ§ª å•é¡Œï¼š\", query_input[\"question\"])\n",
    "\n",
    "response = qa_chain_with_memory.invoke(\n",
    "    query_input,\n",
    "    config={\"configurable\": {\"session_id\": session_id}}  # âœ… åŠ ä¸Šè¨˜æ†¶ç®¡ç†\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– å›ç­”ï¼š\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å•é¡Œï¼š å“ªä¸€çµ„åˆé‡‘çš„è¡¨ç¾æœ€å¥½ï¼Ÿ\n",
      "ğŸ¤– å›ç­”ï¼š è¦ç¡®å®šå“ªç§åˆé‡‘è¡¨ç°æœ€å¥½ï¼Œéœ€è¦æ ¹æ®ç‰¹å®šçš„æ€§èƒ½æŒ‡æ ‡è¿›è¡Œæ¯”è¾ƒï¼Œä¾‹å¦‚å¼ºåº¦ã€å»¶å±•æ€§ã€è€è…èš€æ€§ç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§åˆé‡‘çš„æ€§èƒ½æ¯”è¾ƒï¼ŒåŸºäºç°æœ‰æ–‡çŒ®ï¼š\n",
      "\n",
      "| åˆé‡‘ç±»å‹ | å¼ºåº¦ (MPa) | å»¶å±•æ€§ (%) | è€è…èš€æ€§ | å‚è€ƒæ–‡çŒ® |\n",
      "|----------|------------|------------|----------|----------|\n",
      "| CoCrFeMnNi é«˜ç†µåˆé‡‘ | 600-700    | 50-60     | è‰¯å¥½     | [2] æ¥æºï¼š..\\PDF\\Influence-of-pre-deformation-on-the-precipitation-characte_2021_Journal-of-A.pdfï¼Œç¬¬ 10 é¡µ |\n",
      "| FeCoNiCrTi0.2 é«˜ç†µåˆé‡‘ï¼ˆåœ¨å®¤æ¸©å’Œä½æ¸©ä¸‹ï¼‰ | >1000      | >20       | ä¼˜ç§€     | [3] æ¥æºï¼š..\\PDF\\Cryogenic-strengthening-of-Fe27Co24Ni23Cr26-high-entr_2024_Materials-Science.pdfï¼Œç¬¬ 11 é¡µ |\n",
      "\n",
      "ä»ä¸Šè¿°è¡¨æ ¼å¯ä»¥çœ‹å‡ºï¼ŒFeCoNiCrTi0.2 é«˜ç†µåˆé‡‘åœ¨å¼ºåº¦å’Œä½æ¸©æ¡ä»¶ä¸‹çš„è¡¨ç°ä¼˜äº CoCrFeMnNi åˆé‡‘ã€‚ç„¶è€Œï¼Œå…·ä½“å“ªä¸ªåˆé‡‘â€œæœ€å¥½â€è¿˜å–å†³äºåº”ç”¨åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœéœ€è¦æ›´é«˜çš„å»¶å±•æ€§è€Œä¸æ˜¯æé™å¼ºåº¦ï¼Œé‚£ä¹ˆ CoCrFeMnNi åˆé‡‘å¯èƒ½æ›´é€‚ç”¨ã€‚\n",
      "\n",
      "è¯·æ³¨æ„ï¼Œè¿™åªæ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¯”è¾ƒï¼Œå®é™…é€‰æ‹©åº”è€ƒè™‘æ›´å¤šå› ç´ ä»¥åŠå…·ä½“åº”ç”¨éœ€æ±‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "query_input = {\n",
    "    \"question\": \"å“ªä¸€çµ„åˆé‡‘çš„è¡¨ç¾æœ€å¥½ï¼Ÿ\",\n",
    "    \"top_k\": 3\n",
    "}\n",
    "\n",
    "print(\"ğŸ§ª å•é¡Œï¼š\", query_input[\"question\"])\n",
    "\n",
    "response = qa_chain_with_memory.invoke(\n",
    "    query_input,\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– å›ç­”ï¼š\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_memory(chain, question: str, session_id: str = \"default\", top_k: int = 5):\n",
    "    query_input = {\"question\": question, \"top_k\": top_k}\n",
    "    print(\"ğŸ§ª å•é¡Œï¼š\", question)\n",
    "    response = chain.invoke(query_input, config={\"configurable\": {\"session_id\": session_id}})\n",
    "    print(\"ğŸ¤– å›ç­”ï¼š\", response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å•é¡Œï¼š è«‹å•åœ¨ç›®å‰çš„é«˜ç†µåˆé‡‘æ‡‰ç”¨ä¸­ï¼Œå“ªäº›å…ƒç´ çµ„åˆå¸¸è¦‹æ–¼å‚¬åŒ–åŠ‘ï¼Ÿ\n",
      "ğŸ¤– å›ç­”ï¼š åœ¨é«˜ç†µåˆé‡‘ï¼ˆHEAï¼‰å‚¬åŒ–åŠ‘çš„æ‡‰ç”¨ä¸­ï¼Œå¸¸è¦‹çš„å…ƒç´ çµ„åˆåŒ…æ‹¬å¤šç¨®éæ¸¡é‡‘å±¬å’Œè²´é‡‘å±¬ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è¦‹çš„å…ƒç´ çµ„åˆï¼š\n",
      "\n",
      "1. **CoMoFeNiCu**ï¼šé€™ç¨®çµ„åˆè¢«ç”¨æ–¼æ°¨åˆ†è§£åæ‡‰ï¼Œé¡¯ç¤ºå‡ºé«˜æ´»æ€§å’Œç©©å®šæ€§ã€‚[ä¾†æºï¼šYu, 2022, Carbon Energyï¼Œç¬¬22é ]\n",
      "\n",
      "2. **PtPdRhRuCe**ï¼šé€™äº›å…ƒç´ è¢«ç”¨æ–¼æ°¨æ°§åŒ–åæ‡‰ï¼Œåœ¨é«˜æº«ä¸‹é¡¯ç¤ºå‡ºå„ªç•°çš„è½‰åŒ–ç‡å’Œé¸æ“‡æ€§ã€‚[ä¾†æºï¼šYu, 2022, Carbon Energyï¼Œç¬¬90é ]\n",
      "\n",
      "3. **RuRhCoNiIr**ï¼šæ­¤äº”å…ƒåˆé‡‘åœ¨æ°¨åˆ†è§£ä¸­è¡¨ç¾å‡ºè‰²ï¼Œæ˜¯ä¸€ç¨®æœ‰æ•ˆä¸”æˆæœ¬è¼ƒä½çš„æ›¿ä»£å“ã€‚[ä¾†æºï¼šYu, 2022, Carbon Energyï¼Œç¬¬21é ]\n",
      "\n",
      "4. **AuAgCuPdSi** å’Œ **IrCuPd** ç­‰å¤šå…ƒç´ç±³çµæ§‹ï¼Œè¢«èªç‚ºå…·æœ‰è¨­è¨ˆç´ç±³è£ç½®çš„æ½›åŠ›ã€‚[ä¾†æºï¼šYu, 2022, Carbon Energyï¼Œç¬¬8é ]\n",
      "\n",
      "5. **AuWCoNiPtRuMoPdRhFeCrIrSnMn** ç­‰15å…ƒç´ HEAsï¼Œç”¨æ–¼ç©©å®šæ˜“æ°§åŒ–æ°§åŒ–ç‰©ã€‚[ä¾†æºï¼šYu, 2022, Carbon Energyï¼Œç¬¬12é ]\n",
      "\n",
      "6. **AgAuCuPdPt å’Œ CoCuGaNiZn** è¢«è¨ˆç®—é æ¸¬ç‚ºå…·æœ‰é«˜é¸æ“‡æ€§å’Œæ´»æ€§çš„COé‚„åŸå‚¬åŒ–åŠ‘ã€‚[ä¾†æºï¼šYu, 2022, Carbon Energyï¼Œç¬¬20-21é ]\n",
      "\n",
      "é€™äº›çµ„åˆå±•ç¤ºäº†HEAå‚¬åŒ–åŠ‘åœ¨ä¸åŒåæ‡‰ä¸­çš„æ½›åŠ›ï¼Œç‰¹åˆ¥æ˜¯åœ¨éœ€è¦å¤šé‡æ´»æ€§ä½é»ä»¥ä¿ƒé€²è¤‡é›œã€å¤šæ­¥é©Ÿåæ‡‰æ™‚ã€‚\n",
      "ğŸ§ª å•é¡Œï¼š å“ªä¸€çµ„åˆé‡‘æ€§èƒ½æœ€å¥½ï¼Ÿ\n",
      "ğŸ¤– å›ç­”ï¼š è¦æ¯”è¼ƒä¸åŒåˆé‡‘çš„æ€§èƒ½ï¼Œæˆ‘å€‘éœ€è¦è€ƒæ…®å¤šç¨®å› ç´ ï¼ŒåŒ…æ‹¬å¼·åº¦ã€å»¶å±•æ€§ã€è€é«˜æº«æ€§ã€è€è…è•æ€§ç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è¦‹çš„é«˜ç†µåˆé‡‘ï¼ˆHEAï¼‰åŠå…¶æ€§èƒ½ç‰¹é»ï¼š\n",
      "\n",
      "1. **CoCrFeMnNi**ï¼š\n",
      "   - æ“æœ‰è‰¯å¥½çš„å¼·åº¦å’ŒéŸŒæ€§ï¼Œé©ç”¨æ–¼å¾å®¤æº«åˆ°ä½æº«ç’°å¢ƒã€‚\n",
      "   - åœ¨é«˜æº«ä¸‹ï¼Œå–®ç›¸HEAçš„å¼·åº¦ç›¸å°è¼ƒå¼±ï¼Œéœ€è¦è€ƒæ…®æ“´æ•£é©…å‹•çš„ç›¸è®Šå’Œè •è®Šè¡Œç‚ºã€‚[ä¾†æºï¼š5]\n",
      "\n",
      "2. **AlCoCrFeNiTi**ï¼š\n",
      "   - å…·æœ‰å„ªç•°çš„å®¤æº«æ©Ÿæ¢°æ€§èƒ½ã€‚\n",
      "   - æ·»åŠ Alå¾Œæœƒå½±éŸ¿çµæ§‹æ¼”åŒ–å’Œæ‹‰ä¼¸æ€§èƒ½ã€‚[ä¾†æºï¼š31]\n",
      "\n",
      "3. **(Co30Fe45Ni25)0.8(Al40Si60)0.2**ï¼š\n",
      "   - çµåˆäº†è‰¯å¥½çš„æ©Ÿæ¢°ã€é›»æ°£å’Œç£æ€§è³ªï¼šé«˜å±ˆæœå¼·åº¦1636 MPaï¼Œé«˜é›»é˜»ç‡68 Î¼Î©Â·cmï¼Œç›¸å°è¼ƒé«˜çš„é£½å’Œæ„Ÿæ‡‰1.24 Teslaï¼Œä»¥åŠç›¸å°ä½çŸ¯é ‘åŠ›59.7 A/mã€‚[ä¾†æºï¼š7]\n",
      "\n",
      "4. **Fe27Co24Ni23Cr26**ï¼š\n",
      "   - é©ç”¨æ–¼å¾ä½æº«åˆ°é«˜æº«å¤šåŠŸèƒ½æ‡‰ç”¨ï¼Œæœ‰è‘—å„ªç•°çš„å¼·-å»¶å±•å”åŒæ•ˆæ‡‰å’Œæ‡‰è®Šç¡¬åŒ–èƒ½åŠ›ã€‚[ä¾†æºï¼š19]\n",
      "\n",
      "5. **Al0.3CoCrFeNi**ï¼š\n",
      "   - å¯ä»¥é€šéèª¿æ•´å¾®è§€çµæ§‹å¯¦ç¾å“è¶Šçš„æ©Ÿæ¢°æ€§èƒ½ï¼Œå¦‚è¶…ç´°æ™¶ç²’çµæ§‹å¯å¢å¼·å…¶æŠ—æ‹‰ä¼¸èƒ½åŠ›ã€‚[ä¾†æºï¼š48]\n",
      "\n",
      "é€™äº›åˆé‡‘å„æœ‰å…¶ç¨ç‰¹å„ªå‹¢ï¼Œå…·é«”å“ªä¸€çµ„åˆé‡‘æœ€å¥½å–æ±ºæ–¼æ‚¨æ‰€é—œå¿ƒæˆ–éœ€è¦è§£æ±ºå•é¡Œä¸­çš„å…·é«”éœ€æ±‚ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨éœ€è¦åœ¨æ¥µç«¯ä½æº«ä¸‹ä½¿ç”¨ææ–™ï¼Œå¯èƒ½é¸æ“‡å…·æœ‰è‰¯å¥½éŸŒæ€§çš„ææ–™æ›´ç‚ºé‡è¦ï¼›è€Œå¦‚æœæ˜¯åœ¨è…è•ç’°å¢ƒä¸­ä½¿ç”¨ï¼Œå‰‡è€è…è•æ€§çš„è¡¨ç¾æœƒæ›´ç‚ºé—œéµã€‚\n",
      "\n",
      "å¦‚éœ€é€²ä¸€æ­¥æ¯”è¼ƒæˆ–é¸æ“‡æŸä¸€ç‰¹å®šç”¨é€”ä¸Šçš„æœ€ä½³ææ–™ï¼Œå¯ä»¥æä¾›æ›´å¤šè©³ç´°ä¿¡æ¯ä»¥ä¾¿é€²è¡Œé‡å°æ€§çš„åˆ†æã€‚\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'è¦æ¯”è¼ƒä¸åŒåˆé‡‘çš„æ€§èƒ½ï¼Œæˆ‘å€‘éœ€è¦è€ƒæ…®å¤šç¨®å› ç´ ï¼ŒåŒ…æ‹¬å¼·åº¦ã€å»¶å±•æ€§ã€è€é«˜æº«æ€§ã€è€è…è•æ€§ç­‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è¦‹çš„é«˜ç†µåˆé‡‘ï¼ˆHEAï¼‰åŠå…¶æ€§èƒ½ç‰¹é»ï¼š\\n\\n1. **CoCrFeMnNi**ï¼š\\n   - æ“æœ‰è‰¯å¥½çš„å¼·åº¦å’ŒéŸŒæ€§ï¼Œé©ç”¨æ–¼å¾å®¤æº«åˆ°ä½æº«ç’°å¢ƒã€‚\\n   - åœ¨é«˜æº«ä¸‹ï¼Œå–®ç›¸HEAçš„å¼·åº¦ç›¸å°è¼ƒå¼±ï¼Œéœ€è¦è€ƒæ…®æ“´æ•£é©…å‹•çš„ç›¸è®Šå’Œè •è®Šè¡Œç‚ºã€‚[ä¾†æºï¼š5]\\n\\n2. **AlCoCrFeNiTi**ï¼š\\n   - å…·æœ‰å„ªç•°çš„å®¤æº«æ©Ÿæ¢°æ€§èƒ½ã€‚\\n   - æ·»åŠ Alå¾Œæœƒå½±éŸ¿çµæ§‹æ¼”åŒ–å’Œæ‹‰ä¼¸æ€§èƒ½ã€‚[ä¾†æºï¼š31]\\n\\n3. **(Co30Fe45Ni25)0.8(Al40Si60)0.2**ï¼š\\n   - çµåˆäº†è‰¯å¥½çš„æ©Ÿæ¢°ã€é›»æ°£å’Œç£æ€§è³ªï¼šé«˜å±ˆæœå¼·åº¦1636 MPaï¼Œé«˜é›»é˜»ç‡68 Î¼Î©Â·cmï¼Œç›¸å°è¼ƒé«˜çš„é£½å’Œæ„Ÿæ‡‰1.24 Teslaï¼Œä»¥åŠç›¸å°ä½çŸ¯é ‘åŠ›59.7 A/mã€‚[ä¾†æºï¼š7]\\n\\n4. **Fe27Co24Ni23Cr26**ï¼š\\n   - é©ç”¨æ–¼å¾ä½æº«åˆ°é«˜æº«å¤šåŠŸèƒ½æ‡‰ç”¨ï¼Œæœ‰è‘—å„ªç•°çš„å¼·-å»¶å±•å”åŒæ•ˆæ‡‰å’Œæ‡‰è®Šç¡¬åŒ–èƒ½åŠ›ã€‚[ä¾†æºï¼š19]\\n\\n5. **Al0.3CoCrFeNi**ï¼š\\n   - å¯ä»¥é€šéèª¿æ•´å¾®è§€çµæ§‹å¯¦ç¾å“è¶Šçš„æ©Ÿæ¢°æ€§èƒ½ï¼Œå¦‚è¶…ç´°æ™¶ç²’çµæ§‹å¯å¢å¼·å…¶æŠ—æ‹‰ä¼¸èƒ½åŠ›ã€‚[ä¾†æºï¼š48]\\n\\né€™äº›åˆé‡‘å„æœ‰å…¶ç¨ç‰¹å„ªå‹¢ï¼Œå…·é«”å“ªä¸€çµ„åˆé‡‘æœ€å¥½å–æ±ºæ–¼æ‚¨æ‰€é—œå¿ƒæˆ–éœ€è¦è§£æ±ºå•é¡Œä¸­çš„å…·é«”éœ€æ±‚ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨éœ€è¦åœ¨æ¥µç«¯ä½æº«ä¸‹ä½¿ç”¨ææ–™ï¼Œå¯èƒ½é¸æ“‡å…·æœ‰è‰¯å¥½éŸŒæ€§çš„ææ–™æ›´ç‚ºé‡è¦ï¼›è€Œå¦‚æœæ˜¯åœ¨è…è•ç’°å¢ƒä¸­ä½¿ç”¨ï¼Œå‰‡è€è…è•æ€§çš„è¡¨ç¾æœƒæ›´ç‚ºé—œéµã€‚\\n\\nå¦‚éœ€é€²ä¸€æ­¥æ¯”è¼ƒæˆ–é¸æ“‡æŸä¸€ç‰¹å®šç”¨é€”ä¸Šçš„æœ€ä½³ææ–™ï¼Œå¯ä»¥æä¾›æ›´å¤šè©³ç´°ä¿¡æ¯ä»¥ä¾¿é€²è¡Œé‡å°æ€§çš„åˆ†æã€‚'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_with_memory(qa_chain_with_memory, \"è«‹å•åœ¨ç›®å‰çš„é«˜ç†µåˆé‡‘æ‡‰ç”¨ä¸­ï¼Œå“ªäº›å…ƒç´ çµ„åˆå¸¸è¦‹æ–¼å‚¬åŒ–åŠ‘ï¼Ÿ\", session_id=\"chen01\", top_k=100)\n",
    "ask_with_memory(qa_chain_with_memory, \"å“ªä¸€çµ„åˆé‡‘æ€§èƒ½æœ€å¥½ï¼Ÿ\", session_id=\"chen01\", top_k=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
